---
section: ml
title: "Заключение"
---

#### Что изучать дальше?

Итак, на этом подходит к концу наше изучение основ машинного обучения. Мы познакомились с базовыми понятиями анализа данных, математических и методологических основ машинного обучения, прошли несколько самых популярных видов моделей обучения с учителем. Конечно, мир машинного обучения далеко не ограничивается этими темами. Все многообразие задач, моделей и алгоритмов машинного обучения невозможно изложить в одной книге. Поэтому на базе полученных знаний любой интересующийся должен продолжить изучение продвинутых разделов самостоятельно. В этом небольшой главе мы попробуем обрисовать общую картину необходимых навыков и пути развития специалиста в науках по данным с упором в машинное обучение.

##### Фундаментальная подготовка

Для начала обратимся к необходимым базовым знаниям в других областях наук. Что нужно знать и изучать, чтобы эффективно развиваться в машинном обучении? Мы уже немного говорили об этом в первой части книги, но сейчас более точно перечислим конкретные навыки, полезные для любого аналитика данных.

В первую очередь, это знания в области математической статистики. Вот на какие темы стоит обратить особое внимание:

- Случайность, случайные переменные, случайные выборки.
- Понятие вероятности: распределение вероятности, условные вероятности и теорема Байеса, понятие независимости.
- Распространенные непрерывные распределения вероятностей: нормальное (Гауссово), равномерное, экспоненциальное,бета-распределение, распределение Дирихле, хи-квадрат.
- Распространенные дискретные распределения вероятностей: равномерное, биномиальное, мультиномиальное, геометрическое, гипергеометрическое, распределение Пуассона.
- Важные статистические законы: закон больших чисел, центральная предельная теорема.
- Выборочные статистики: математическое ожидание и среднее, дисперсия и среднеквадратическое отклонение, ковариация и корреляция, медиана, мода, квартили.
- Статистические оценки: метод максимального правдоподобия, метод наименьших квадратов.
- Проверка статистических гипотез: тест хи-квадрат, Фишера, Стьюдента, доверительные интервалы, метод Монте-Карло.

Не менее важна подготовка и в области информатики. В первую очередь это программирование и смежные темы:

- Базовое программирование: выражения, переменные, структуры данных, функции, ООП.
- Экосистема Python: библиотеки numpy, pandas, matplotlib, seaborn, виртуальные окружения, pip, jupyter notebook, PEP 8.
- Форматы хранения данных: JSON, XML, CSV, XLS, реляционные и нереляционные СУБД, SQL, оператор JOIN.
- Регулярные выражения.
- Источники данных: парсеры и скрейперы, Kaggle, PapersWithCode, Awesome public datasets.
- Методы и средства визуализации данных: дашборды, Web-интерфейсы (d3.js, dash), Plotly, Bokeh.
- Линейная алгебра, матричные операции и параллельное программирование, вычисления на графических ядрах.

Конечно, это довольно большой объем информации и его не освоить за один день. Но надо понимать, что развитие специалиста требует не столько глубокого заучивания всех деталей во всех этих разделах, сколько базового понимания основных принципов и механизмов. Поэтому один раз изучив, например, методы проверки статистических гипотез, главное навсегда понять, что это, зачем оно нужно, где применяется и как работает. А все детали: формулы, методы, примеры кода можно найти непосредственно в процессе работы над практическими задачами. 

Помните, что понимание и осознание всегда лучше заучивания.

##### Машинное обучение

Мы с вами изучили базовые концепции машинного обучения, такие как атрибуты и признаки, типы шкал, функции ошибки и градиентный спуск, недо- и переобучение, обучающий, валидационный и тестовые наборы данных, метрики эффективности. Кроме того изучили основные модели обучения с учителем: задачи регрессии и классификации, линейные и полиномиальные модели, методы опорных векторов, деревья решений, наивный Байес, ближайшие соседи. Что изучать дальше?

Среди неизученных видов моделей и задач машинного обучения можно выделить три большие части:

- обучение без учителя, 
- ансамблевые модели,
- обучение с подкреплением.

Обучение без учителя - это набор моделей и методов, которые решают задачи нахождения внутренней структуры в данных. Их ключевое отличие от задач обучения без учителя состоит в том, что они не сводятся к предсказанию (моделированию) определенной целевой переменной. Поэтому в датасете не должны присутствовать "правильные ответы". Существует несколько типовых задач обучения без учителя - кластеризация, обнаружение аномалий, понижение размерностей, вывод ассоциативных правил, рекомендательные системы.

Ансамблевые модели - это способ строить модель, состоящую из нескольких моделей. Например, можно построить на одном датасете несколько разных типов моделей и выбирать то предсказание, которое дает большинство моделей. Такой подход называется _voting classifier_. Можно объединять модели другими способами. Среди ансамблей моделей выделяют такие типы как: бустинг, бэггинг, стакинг. На основе ансамблей работают множество широко известных моделей, такие как XGBoost и CatBoost. Кроме того ансамблем является такая модель, как случайный лес. Использование сразу нескольких моделей может помочь повысить эффективность и надежность предсказаний машинного обучения.

Обучение с подкреплением - это достаточно специфическая область машинного обучения, в ходе которого модель обучается не напрямую из готовых данных, а взаимодействуя со средой. Эта среда может дать модели положительную или отрицательную обратную связь (подкрепление). Причем это подкрепление может наступать в произвольные моменты времени. В настоящее время обучение с подкреплением используется в системах принятия решений, в агентном моделировании, в ботах для компьютерных игр, диалоговых системах и чат-ботах. Самым известным алгоритмом обучения с подкреплением является Q-learning.

Следующий шаг - освоение глубокого обучения. Это ве про искусственные нейронные сети. Начать следует с базовых принципов нейронных сетей: модели нейрона, функции активации, метод обратного распространения ошибки, проблема исчезающих градиентов. После этого следует переходить к изучению различных архитектур нейронных сетей, от простых до более сложных:

- сети прямого распространения (перцептроны);
- сверточные нейронные сети;
- рекуррентные нейронные сети;
- автоэнкодеры;
- генеративно-состязательные сети;
- трансформеры;
- сети с механизмом внимания. 

На самом деле их еще гораздо больше, но это - самые популярные и часто использующиеся на практике. С них можно начать.

После освоения всех видов моделей машинного обучения можно приступить к изучения различных предметных областей, в которых применяется машинное обучение. Ведь каждая из них имеет свои особенности: структуру данных, приемы их обработки и векторизации, типичные подходы к моделированию, архитектуры моделей. Вот примерный (далеко неполный) список таких областей и самые распространенные прикладные задачи в них:

- Компьютерное зрение: классификация изображений, обнаружение объектов, генерация изображений.
- Обработка естественных текстов: вопрос-ответные системы машинный перевод, анализ тональности, генерация текстов.
- Анализ временных рядов: классификация рядов, прогнозирование, сжатие данных.
- Графовая аналитика: графовые вложения, классификация графов, графы знаний.
- Анализ речи: распознавание речи, синтез речи, генерация диалогов, анализ эмоций, идентификация по голосу.
- Медицина: синтез белков, медицинская диагностика, синтез лекарств, диагностика по изображениям.
- Игры: разработка интеллектуальных ботов, игровые движки, генерация игровых ресурсов.

После этого рекомендуем обратить свое внимание на специализированные методологии машинного обучения. Они решают очень специфические задачи. Для их даже приблизительного понимания нужно хорошо знать классическую методику машинного обучения, которую мы и обсуждали в этом учебнике. Примерами таких специальных задач (список актуален на начало 2023 года, так как постоянно возникают новые области) могут быть следующие:

- трансферное обучение (transfer learning);
- автоматизированное машинное обучение (AutoML);
- федеративное обучение (federated learning);
- поиск архитектуры нейронных сетей (NAS);
- операции разработки систем машинного обучения (MLOps);
- мультизадачное и мультимодальное обучение;

Этот путь не имеет завершения, у него открытый финал. Всегда есть еще что-то для изучения, поэтому желаю удачи в этом интересном мире машинного обучения!

#### Список рекомендуемой литературы

##### Официальная документация

1. Библиотека классического машинного обучения _sklearn_: https://scikit-learn.org/stable/user_guide.html
1. Библиотека операций над многомерными массивами _numpy_: https://numpy.org/doc/stable/user/
1. Библиотека анализа табличных данных _pandas_: https://pandas.pydata.org/docs/user_guide/
1. Библиотека базовой визуализации _matplotlib_: https://matplotlib.org/stable/users/index
1. Библиотека продвинутой визуализации для анализа данных _seaborn_: https://seaborn.pydata.org/tutorial.html
1. Библиотека продвинутой визуализации для машинного обучения _yellowbrick_: https://www.scikit-yb.org/en/latest/

##### Книги и учебники

1. А. Мюллер, С. Гвидо. Введение в машинное обучение с помощью Python - 2016 год (480 страниц)
1. В. Лакшманан, С. Робинсон, М.Мун. Машинное обучение. Паттерны проектирования - 2022 год (445 страниц)
1. Т. Казанцев. Искусственный интеллект и Машинное обучение. Основы программирования на Python - 2020 год (170 страниц)
1. Э. Траск. Грокаем глубокое обучение - 2019 год (352 страницы)
1. A. Geron. Hand on Machine Learning with scikit-learn and Tensorflow - 2017 год (564 страницы)
1. C. Albon. Machine learning with Python Handbook - 2018 год (427 страниц)
1. L.P. Coelho, W. Richert. Building machine learning systems with Python - 2015 год (326 страниц)
1. J. Grus. Data science from scratch - 2015 год (330 страниц)
1. W. McKiney. Pandas: powerful Python data analysis toolkit - 2016 год (1971 страница)

##### Сайты и справочники

1. Kaggle - соревнования и материалы по машинному обучению, большое коммьюнити: https://www.kaggle.com/
1. Papers With Code - репозиторий научных статей и кода по машинному обучению: https://paperswithcode.com/
1. OpenML - открытая лаборатория по машинному обучению: https://www.openml.org/
1. Towards data science - тематический блог по машинному обучению: https://towardsdatascience.com/
1. Loginom - тематический блог отечественного разработчика программного обеспечения: https://loginom.ru/blog
1. Data Analytics - тематический блог по анализу данных, машинному обучению и другим смежным темам: https://vitalflux.com/
1. Дорожная карта развития специалиста по машинному обучению: https://i.am.ai/roadmap
1. Тематический блог на Хабре: https://habr.com/ru/hub/artificial_intelligence/
